
## 1. 논문 정보

* **논문 제목**: NEMOTRON-CC-MATH: A 133 BILLION-TOKEN-SCALE HIGH QUALITY MATH PRETRAINING DATASET
* **저자**: Rabeeh Karimi Mahabadi, Sanjeev Satheesh, Shrimai Prabhumoye, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro (NVIDIA, Boston University 소속)
* **발표**: 2025년 8월 20일 arXiv에 공개

## 2. 연구 목적

이 연구의 핵심 목적은 **대규모 언어 모델(LLM)의 수학적 및 일반적 추론 능력을 향상시키기 위해, 웹에서 수집한 데이터로 구성된 대규모의 고품질 수학 전용 사전 훈련(pretraining) 데이터셋을 구축**하는 것입니다. 기존의 웹 기반 수학 데이터셋들이 가진 품질 저하 문제를 해결하기 위해, 수학 공식과 코드 구조를 온전히 보존하는 새로운 데이터 추출 및 정제 파이프라인을 제안하고, 이를 통해 생성된 데이터셋의 우수성을 실험적으로 증명하는 것을 목표로 합니다.

## 3. 연구 배경

* **LLM 성능과 데이터 품질의 상관관계**: LLM은 수학이나 코드와 같이 구조화된 고품질 데이터로 사전 훈련될 때 추론 능력이 크게 향상됩니다. 즉, 데이터의 질과 양이 모델 성능에 직접적인 영향을 미칩니다.
* **기존 수학 데이터셋의 한계**:
    * **Proprietary 데이터셋**: OpenAI의 O1이나 DeepSeek-R1과 같은 최신 모델들은 비공개(proprietary) 수학 데이터셋을 사용하여 일반 연구자들이 접근하고 활용하기 어렵습니다.
    * **오픈소스 데이터셋의 품질 문제**: OpenWebMath(OWM), FineMath와 같은 기존 오픈소스 데이터셋들은 Common Crawl에서 데이터를 추출할 때 사용되는 파이프라인의 한계로 인해 품질이 저하됩니다. HTML을 텍스트로 변환하는 과정에서 수학 공식(예: LaTeX, MathML)이나 코드 블록의 구조가 손상되거나 아예 누락되는 경우가 많았습니다.
* **웹 데이터의 복잡성**: 웹상의 수학 표현은 MathJax, KaTeX, MathML, 이미지 등 형식이 매우 다양하며, 고정된 규칙(heuristic) 기반의 추출 방식으로는 이를 안정적으로 처리하기 어렵습니다.

## 4. 방법론: Nemotron-CC-Math 구축 파이프라인

본 연구는 이러한 문제를 해결하기 위해 독창적이고 확장 가능한 데이터 처리 파이프라인을 설계했습니다. 전체 과정은 아래와 같습니다.


1.  **URL 수집 (URL Filtering)**: 처음부터 Common Crawl 전체를 스캔하는 대신, 기존의 수학 관련 오픈소스 데이터셋(MegaMath, FineMath, OWM 등)에서 이미 한 차례 필터링된 URL 목록을 활용했습니다. 이를 통해 고품질의 수학 관련 웹페이지에 집중할 수 있었습니다.
2.  **HTML 원본 다운로드**: 2014년부터 2024년까지의 98개 Common Crawl 스냅샷에서 해당 URL들의 원본 HTML 문서를 다운로드하여 약 2억 3천만 개의 문서를 확보했습니다.
3.  **1차 텍스트 변환 (Lynx Processing)**: 기존 파서 대신 텍스트 기반 웹 브라우저인 **Lynx**를 사용했습니다. Lynx는 웹페이지의 레이아웃 규칙을 실행하여 렌더링하므로, 수학 공식의 구조나 코드의 들여쓰기(indentation)를 파괴하지 않고 원본에 가깝게 텍스트로 변환할 수 있습니다. 이것이 본 논문의 핵심적인 기술적 차별점 중 하나입니다.
4.  **LLM 기반 정제 및 표준화 (Refining Text)**: Lynx로 변환된 텍스트에는 여전히 네비게이션 바, 푸터 등 불필요한 내용(boilerplate)이 포함되어 있습니다. 이를 제거하고, 다양한 형태의 수학 표현(MathJax, MathML, 이미지 태그 등)을 **일관된 LaTeX 형식으로 표준화**하기 위해 경량 LLM인 **Phi-4 (14B)**를 사용했습니다. 이 LLM 기반 정제 방식은 규칙 기반보다 훨씬 유연하고 정확하게 핵심 콘텐츠를 추출합니다.
5.  **품질 분류 (Quality Classification)**: FineMath에서 사용된 분류기를 이용해 각 문서의 품질을 5점 척도로 평가했습니다. 이를 바탕으로 두 가지 버전의 데이터셋을 구축했습니다.
    * **Nemotron-CC-Math-3+**: 3점 이상, 1,332억 토큰
    * **Nemotron-CC-Math-4+**: 4점 이상, 523억 토큰 (최고 품질)
6.  **중복 제거 및 오염 제거 (Deduplication & Decontamination)**: MinHash LSH를 사용하여 유사도가 0.8 이상인 문서들을 제거했습니다. 또한, MMLU, MATH, GSM8K와 같은 평가 벤치마크 데이터와의 중복을 피하기 위해, 임베딩 기반 코사인 유사도가 0.9 이상인 문서를 제거하는 오염 제거 절차를 수행했습니다.

## 5. 실험 설정

* **베이스 모델**: 9조(9T) 토큰으로 사전 훈련된 **Nemotron-T 8B** 모델을 사용했습니다.
* **비교 데이터셋**: MegaMath, OpenWebMath(OWM), FineMath 등 기존의 주요 오픈소스 수학 데이터셋과 성능을 비교했습니다.
* **실험 방식 (Annealing Ablations)**: 베이스 모델에 각 수학 데이터셋을 30% 비율로 혼합한 데이터로 추가 훈련(1000억 또는 3000억 토큰)을 진행했습니다. 이를 통해 각 데이터셋이 모델 성능에 미치는 영향을 독립적으로 평가했습니다.
* **평가 벤치마크**:
    * **수학**: MATH, GSM8K
    * **코드**: MBPP, HumanEval (+Plus 버전 포함)
    * **일반 지식**: MMLU, MMLU-Pro, MMLU-STEM

## 6. 주요 결과 및 분석

### 주요 결과

Nemotron-CC-Math 데이터셋으로 훈련한 모델은 **수학, 코드, 일반 지식 모든 영역에서 기존 오픈소스 데이터셋으로 훈련한 모델들을 압도**했습니다.

* **1000억 토큰 훈련**: **Nemotron-CC-Math-4+**는 MATH 벤치마크에서 FineMath-4+ 대비 **+4.8점**, MegaMath-Pro 대비 **+6.6점** 높은 점수를 기록했습니다.
* **3000억 토큰 훈련**: **Nemotron-CC-Math-3+**는 MATH 벤치마크에서 FineMath-3+ 대비 **+9.6점**, MegaMath-Web 대비 **+12.6점** 높은 점수를 보였습니다. MBPP+ (코드) 벤치마크에서는 FineMath-3+ 대비 **+14.32점**이라는 큰 폭의 성능 향상을 달성했습니다.

### 분석

* **코드 성능 향상의 원인**: Nemotron-CC-Math는 수학뿐만 아니라 코드 생성 능력도 크게 향상시켰습니다. 이는 제안된 파이프라인이 웹페이지 내의 코드 블록과 그 형식을 온전히 보존했기 때문입니다. 데이터셋 분석 결과, Nemotron-CC-Math-3+에는 약 430만 개의 코드 스니펫이 포함되어 있었습니다.
* **LLM 클리너 선택의 타당성**: 다양한 크기의 LLM(DeepSeek-V3 671B, Qwen2.5 72B 등)으로 정제 작업을 테스트한 결과, **가장 작은 Phi-4 (14B) 모델이 비용 효율적이면서도 다른 대형 모델들과 대등하거나 더 나은 성능**을 보였습니다. 이는 웹페이지 정제와 같은 작업이 반드시 거대한 모델을 필요로 하지는 않음을 시사합니다.
* **데이터셋 구성**: 데이터셋의 약 60%는 수학 관련 문서였으며, 컴퓨터 과학(12%), 물리(11%), 통계(7.5%) 등 다양한 과학 기술 분야의 문서들이 포함되어 있었습니다. 주요 출처는 `mathhelpforum.com`, `jiskha.com`, `physicsforums.com`과 같은 Q&A 및 토론 포럼이었습니다.

## 7. 결론

본 연구는 **Lynx와 LLM을 결합한 혁신적인 파이프라인**을 통해, 기존의 한계를 극복하는 **대규모 고품질 수학 데이터셋 Nemotron-CC-Math**를 성공적으로 구축했습니다. 이 데이터셋은 LLM의 수학, 코드, 일반 추론 능력을 전반적으로 크게 향상시켰으며, 특히 최고 품질의 서브셋인 Nemotron-CC-Math-4+는 기존 최고 품질 데이터셋(FineMath-4+)보다 **5.5배 더 큰 규모**를 자랑합니다.

## 8. 시사점 및 향후 연구 방향

* **시사점**:
    * **데이터 품질의 중요성**: 단순한 데이터의 양보다 잘 정제된 고품질 데이터가 모델 성능 향상에 훨씬 효과적임을 보여줍니다.
    * **도메인 독립적 파이프라인**: 제안된 파이프라인은 특정 도메인에 국한되지 않으므로, 화학, 법률, 의학과 같은 다른 전문 분야의 고품질 데이터셋을 구축하는 데에도 활용될 수 있는 잠재력을 가집니다.
* **향후 연구 방향**:
    * 본 파이프라인을 다른 기술 분야에 적용하여 전문화된 LLM을 개발하는 연구를 진행할 수 있습니다.
    * 데이터 정제 및 표준화 단계에서 더욱 발전된 LLM을 사용하여 데이터 품질을 한 단계 더 끌어올리는 연구도 가능합니다.

## 9. 한계점

논문에서 명시적으로 한계점을 언급하지는 않았지만, 다음과 같은 점을 고려할 수 있습니다.

* **초기 URL 의존성**: 파이프라인의 시작점이 기존에 커뮤니티에서 필터링한 데이터셋의 URL에 의존하므로, 이 목록에 포함되지 않은 새로운 고품질 수학 웹사이트를 발견하기는 어렵습니다.
* **분류기 및 LLM 성능 의존성**: 데이터의 최종 품질은 품질 분류기(FineMath classifier)와 정제용 LLM(Phi-4)의 성능에 의존적입니다. 이러한 도구들이 가진 편향이나 오류가 데이터셋에 영향을 미칠 수 있습니다.

## 10. Figure/Table 요약

* **Figure 1**: Nemotron-CC-Math 구축 파이프라인의 전체 과정을 시각적으로 보여줍니다. Common Crawl에서 시작하여 URL 필터링, Lynx 처리, LLM 정제, 중복 제거를 거쳐 최종 데이터셋이 만들어지는 흐름과, 데이터셋의 주제별 분포(수학 60.28% 등)를 파이 차트로 나타냅니다.
* **Figure 2**: 웹 HTML에서 수학 공식이 얼마나 다양한 형태로 나타나는지(LaTeX, pre 태그, MathML, 이미지 태그 등) 보여주고, LLM을 통해 이를 일관된 LaTeX 형식으로 표준화하는 과정을 설명합니다.
* **Table 1**: Nemotron-CC-Math를 다른 주요 수학 데이터셋과 토큰 수, 문서 수 측면에서 비교합니다. Nemotron-CC-Math가 규모 면에서 월등히 크다는 것을 보여줍니다.
* **Table 2**: **핵심 결과 테이블**입니다. 1000억 및 3000억 토큰 추가 훈련 후, 각 데이터셋으로 훈련된 모델의 벤치마크 성능을 비교합니다. Nemotron-CC-Math가 모든 벤치마크에서 가장 우수한 성능을 기록했음을 명확히 보여줍니다.
* **Table 3**: 정제 작업에 사용될 LLM을 선택하기 위한 Ablation 연구 결과입니다. 작은 모델인 Phi-4가 대형 모델들과 대등하거나 더 나은 성능을 보여주어 최종 모델로 선택되었음을 뒷받침합니다.
* **Table 4**: 데이터셋에 가장 많이 포함된 상위 20개 웹사이트 도메인을 문서 수와 문자 수 기준으로 보여줍니다.

## 11. Appendix 요약

* **Appendix A.1 & A.4**: 데이터셋의 주제를 분류하고(A.1), HTML 텍스트를 정제하고 수학 공식을 표준화하는 데(A.4) 사용된 **정확한 프롬프트(prompt)**를 제공합니다. 이는 연구의 재현성을 높이는 중요한 정보입니다.
* **Appendix A.2**: **매우 중요한 부분**으로, 데이터셋의 품질을 질적으로 비교합니다.
    * **MegaMath-Pro의 저품질 샘플**: 의미 없이 동일한 문장이 반복되는 'degenerate' 샘플을 보여주며 기존 데이터셋의 품질 문제를 지적합니다.
    * **Side-by-side 비교**: 동일한 웹페이지를 기존 파이프라인(OWM, MegaMath 등)과 자신들의 파이프라인으로 처리한 결과를 나란히 보여줍니다. 기존 방식들은 코드 블록을 삭제하거나 수학 공식을 깨뜨리는 반면, Nemotron-CC-Math의 파이프라인은 이를 온전히 보존하는 것을 시각적으로 증명합니다.
* **Appendix A.3 & A.5**: 실험에 사용된 구체적인 하이퍼파라미터(학습률, 배치 사이즈 등)와 사전 훈련 단계별 데이터 혼합 비율을 상세히 기술하여 실험의 투명성과 재현성을 보장합니다.

---